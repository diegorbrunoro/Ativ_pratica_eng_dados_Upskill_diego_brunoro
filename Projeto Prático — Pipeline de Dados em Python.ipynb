{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9799db2b-3f39-45be-8db1-ef56a4da35dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1- ‚öôÔ∏è Setup Inicial ‚Äî Diret√≥rios de Trabalho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b4db442-df26-4c66-b712-37743f51f4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: /tmp/pipeline_api/data/raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"/tmp/pipeline_api\"\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea26d839-6aeb-47f7-a638-4eb12c77c2af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2- ‚öôÔ∏è Configura√ß√£o Inicial do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74c9f0d3-c389-4c9a-a776-c3f548aa1d7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Informe a chave",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# üö® Forma antiga (chumbada) ‚Äî comentada para hist√≥rico\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# OPENWEATHER_KEY = \"-\"   # <- conex√£o antiga (n√£o usar em produ√ß√£o)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ‚úÖ Forma nova (segura) ‚Äî pede a chave em tempo de execu√ß√£o\u001b[39;00m\n\u001b[1;32m     10\u001b[0m OPENWEATHER_KEY \u001b[38;5;241m=\u001b[39m getpass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCole sua OPENWEATHER_KEY: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m OPENWEATHER_KEY, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInforme a chave\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# opcional: disponibilizar tamb√©m como vari√°vel de ambiente\u001b[39;00m\n\u001b[1;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENWEATHER_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OPENWEATHER_KEY\n",
      "\u001b[0;31mAssertionError\u001b[0m: Informe a chave"
     ]
    }
   ],
   "source": [
    "# === Passo 2 ‚Äî Configura√ß√£o Inicial do Pipeline (27 capitais BR) ===\n",
    "import os, unicodedata, re\n",
    "from datetime import datetime, timezone\n",
    "from getpass import getpass   # para entrada segura\n",
    "\n",
    "# üö® Forma antiga (chumbada) ‚Äî comentada para hist√≥rico\n",
    "# OPENWEATHER_KEY = \"-\"   # <- conex√£o antiga (n√£o usar em produ√ß√£o)\n",
    "\n",
    "# ‚úÖ Forma nova (segura) ‚Äî pede a chave em tempo de execu√ß√£o\n",
    "OPENWEATHER_KEY = getpass(\"Cole sua OPENWEATHER_KEY: \")\n",
    "assert OPENWEATHER_KEY, \"Informe a chave\"\n",
    "\n",
    "# opcional: disponibilizar tamb√©m como vari√°vel de ambiente\n",
    "os.environ[\"OPENWEATHER_KEY\"] = OPENWEATHER_KEY\n",
    "\n",
    "# 27 capitais brasileiras (com acentos corretos)\n",
    "CAPITAIS_BR = [\n",
    "    \"Rio Branco\",\"Macei√≥\",\"Macap√°\",\"Manaus\",\"Salvador\",\"Fortaleza\",\"Bras√≠lia\",\n",
    "    \"Vit√≥ria\",\"Goi√¢nia\",\"S√£o Lu√≠s\",\"Cuiab√°\",\"Campo Grande\",\"Belo Horizonte\",\n",
    "    \"Bel√©m\",\"Jo√£o Pessoa\",\"Curitiba\",\"Recife\",\"Teresina\",\"Rio de Janeiro\",\n",
    "    \"Natal\",\"Porto Alegre\",\"Porto Velho\",\"Boa Vista\",\"Florian√≥polis\",\"S√£o Paulo\",\n",
    "    \"Aracaju\",\"Palmas\"\n",
    "]\n",
    "\n",
    "# fun√ß√£o auxiliar para normalizar (tirar acentos e baixar letras)\n",
    "def strip_accents(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"utf-8\")\n",
    "    return s\n",
    "\n",
    "def city_key(s: str) -> str:\n",
    "    return strip_accents(s).strip().lower()\n",
    "\n",
    "# diret√≥rios (usando a base do passo 1)\n",
    "BASE_DIR = \"/tmp/pipeline_api\"\n",
    "RAW_DIR  = os.path.join(BASE_DIR, \"data\", \"raw\")\n",
    "PROC_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "REP_DIR  = os.path.join(BASE_DIR, \"data\", \"reports\")\n",
    "for p in [RAW_DIR, PROC_DIR, REP_DIR]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "print(\"Exemplo de normaliza√ß√£o:\", \"Bras√≠lia ->\", city_key(\"Bras√≠lia\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af2671c-0c79-4263-abb3-4c67858e5ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3- üå§Ô∏è Extra√ß√£o ‚Äî **OpenWeather (Current Weather)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650c5f38-81f1-4ac7-9134-1f620c77822b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 3 ‚Äî Extra√ß√£o OpenWeather (27 capitais BR) ===\n",
    "import time, json, requests\n",
    "\n",
    "assert OPENWEATHER_KEY, \"Defina OPENWEATHER_KEY\"\n",
    "assert CAPITAIS_BR, \"Lista de capitais vazia\"\n",
    "\n",
    "ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "ok, fail = 0, 0\n",
    "for city in CAPITAIS_BR:\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": f\"{city},BR\", \"appid\": OPENWEATHER_KEY}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        safe_city = re.sub(r\"\\s+\", \"\", strip_accents(city))  # S√£o Paulo -> SaoPaulo\n",
    "        fp = os.path.join(RAW_DIR, f\"weather_{safe_city}_{ts}.json\")\n",
    "        with open(fp, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "        print(f\"[OK] {city}\")\n",
    "        ok += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] {city}: {e}\")\n",
    "        fail += 1\n",
    "    time.sleep(1)  # respeita limite da free tier (60/min)\n",
    "\n",
    "print(f\"\\nResumo OpenWeather: {ok} OK | {fail} falhas | ts={ts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9db557b3-691b-4ede-86c8-dab1a2e2a1b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4- üß™ Transforma√ß√£o ‚Äî **OpenWeather** ‚Üí Tabela Curada + **Parquet particionado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3bb4b2a-dfe9-4565-89f2-68df09b7c012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 4 ‚Äî Transforma√ß√£o Weather ===\n",
    "import glob, json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import shutil\n",
    "\n",
    "# localizar arquivos do √∫ltimo ts\n",
    "weather_files = sorted(glob.glob(os.path.join(RAW_DIR, f\"weather_*_{ts}.json\")))\n",
    "assert weather_files, \"Nenhum weather_* encontrado para este ts.\"\n",
    "\n",
    "rows = []\n",
    "for fp in weather_files:\n",
    "    with open(fp, \"r\") as f:\n",
    "        rows.append(json.load(f))\n",
    "wdf = json_normalize(rows)\n",
    "\n",
    "# 5 transforma√ß√µes m√≠nimas\n",
    "wdf = wdf.dropna(subset=[\"dt\",\"main.temp\",\"main.humidity\",\"name\"])\n",
    "wdf[\"timestamp\"] = pd.to_datetime(wdf[\"dt\"], unit=\"s\", utc=True)\n",
    "wdf[\"temperature_c\"] = wdf[\"main.temp\"] - 273.15\n",
    "wdf[\"humidity\"] = wdf[\"main.humidity\"].astype(\"Int64\")\n",
    "wdf[\"city\"] = wdf[\"name\"].astype(str).str.strip()\n",
    "wdf[\"city_key\"] = wdf[\"city\"].apply(city_key)\n",
    "\n",
    "def hum_cat(x):\n",
    "    if pd.isna(x): return None\n",
    "    x = int(x)\n",
    "    if x < 40: return \"Low\"\n",
    "    if x < 70: return \"Moderate\"\n",
    "    return \"High\"\n",
    "wdf[\"humidity_category\"] = wdf[\"humidity\"].map(hum_cat)\n",
    "\n",
    "wdf[\"timestamp_year\"] = wdf[\"timestamp\"].dt.year\n",
    "wdf[\"timestamp_month\"] = wdf[\"timestamp\"].dt.month\n",
    "\n",
    "weather_curated = wdf[[\n",
    "    \"city\",\"city_key\",\"timestamp\",\"temperature_c\",\"humidity\",\"humidity_category\",\n",
    "    \"timestamp_year\",\"timestamp_month\"\n",
    "]]\n",
    "\n",
    "display(weather_curated.head())\n",
    "\n",
    "OUT_WEATHER = os.path.join(PROC_DIR, \"weather_only.parquet\")\n",
    "if os.path.exists(OUT_WEATHER): shutil.rmtree(OUT_WEATHER)\n",
    "os.makedirs(OUT_WEATHER, exist_ok=True)\n",
    "\n",
    "pa_tbl = pa.Table.from_pandas(weather_curated, preserve_index=False)\n",
    "ds.write_dataset(pa_tbl, base_dir=OUT_WEATHER, format=\"parquet\",\n",
    "                 partitioning=[\"timestamp_year\",\"timestamp_month\"])\n",
    "\n",
    "print(\"Weather parquet salvo em:\", OUT_WEATHER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34a160ec-0465-4317-a9de-b783dbc67a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5- ‚úÖ **Quality Check ‚Äî `weather_only.parquet`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f510f0-ce5e-4d99-9854-c775a38f5a67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 5 ‚Äî Quality Weather Only ===\n",
    "import json\n",
    "\n",
    "weather_ds = ds.dataset(OUT_WEATHER, format=\"parquet\")\n",
    "check_df = weather_ds.to_table().to_pandas()\n",
    "\n",
    "def null_ratios(df):\n",
    "    return {c: float(df[c].isna().mean()) for c in df.columns}\n",
    "\n",
    "q_report = {\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "    \"row_count\": int(len(check_df)),\n",
    "    \"null_ratios\": null_ratios(check_df),\n",
    "    \"temperature_c_range\": {\n",
    "        \"min\": float(check_df[\"temperature_c\"].min()),\n",
    "        \"max\": float(check_df[\"temperature_c\"].max())\n",
    "    },\n",
    "    \"humidity_range\": {\n",
    "        \"min\": int(check_df[\"humidity\"].min()),\n",
    "        \"max\": int(check_df[\"humidity\"].max())\n",
    "    },\n",
    "}\n",
    "\n",
    "rep_fp = os.path.join(REP_DIR, f\"quality_weather_{ts}.json\")\n",
    "with open(rep_fp, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(q_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Quality salvo em:\", rep_fp)\n",
    "display(check_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4969f4f9-18ca-4cfb-8c68-4777a14252a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6- üåé Extra√ß√£o & Transforma√ß√£o ‚Äî **REST Countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cc94179-1585-4213-a2b1-16ed81c5a334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 6 ‚Äî Extra√ß√£o + Transforma√ß√£o REST Countries (fix p/ 27 capitais) ===\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# 1) Buscar REST Countries\n",
    "try:\n",
    "    r = requests.get(\"https://restcountries.com/v3.1/name/brazil?fullText=true\", timeout=30)\n",
    "    r.raise_for_status()\n",
    "    countries_raw = r.json()\n",
    "except Exception as e:\n",
    "    print(\"Erro na API REST Countries, usando fallback m√≠nimo:\", e)\n",
    "    countries_raw = [{\"name\": {\"common\": \"Brazil\"}, \"population\": 203_000_000, \"cca2\": \"BR\"}]\n",
    "\n",
    "cdf = json_normalize(countries_raw)\n",
    "\n",
    "# 2) Isolar Brasil\n",
    "# tenta pelo c√≥digo BR; se n√£o tiver, usa a primeira linha\n",
    "if \"cca2\" in cdf.columns and (cdf[\"cca2\"] == \"BR\").any():\n",
    "    br = cdf[cdf[\"cca2\"] == \"BR\"].iloc[0]\n",
    "else:\n",
    "    br = cdf.iloc[0]\n",
    "\n",
    "country_name = br.get(\"name.common\", \"Brazil\")\n",
    "country_pop  = int(br.get(\"population\", 203_000_000))\n",
    "\n",
    "# 3) Expandir para TODAS as 27 capitais\n",
    "countries_curated = pd.DataFrame({\n",
    "    \"city\": CAPITAIS_BR\n",
    "})\n",
    "countries_curated[\"city_key\"]   = countries_curated[\"city\"].apply(city_key)\n",
    "countries_curated[\"country\"]    = country_name\n",
    "countries_curated[\"population\"] = country_pop\n",
    "\n",
    "print(\"Countries curated (27 linhas esperadas):\", len(countries_curated))\n",
    "display(countries_curated.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68a98788-ff4f-4c54-a896-96dd847e1772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7- üîó JOIN ‚Äî **Weather √ó Countries** + **Parquet Final** + **Quality Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ddf357-c52d-46d7-8d9e-3dd692d3c7e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 7 ‚Äî JOIN Weather x Countries ===\n",
    "weather_df = weather_ds.to_table().to_pandas()\n",
    "weather_df[\"city_key\"] = weather_df[\"city\"].apply(city_key)\n",
    "\n",
    "final_pd = weather_df.merge(countries_curated, on=\"city_key\", how=\"inner\",\n",
    "                            suffixes=(\"_weather\",\"_country\"))\n",
    "final_pd[\"city\"] = final_pd[\"city_weather\"]\n",
    "\n",
    "final_pd[\"timestamp_year\"] = final_pd[\"timestamp\"].dt.year\n",
    "final_pd[\"timestamp_month\"] = final_pd[\"timestamp\"].dt.month\n",
    "\n",
    "final_pd = final_pd[[\n",
    "    \"city\",\"timestamp\",\"temperature_c\",\"humidity\",\"humidity_category\",\n",
    "    \"country\",\"population\",\"timestamp_year\",\"timestamp_month\"\n",
    "]]\n",
    "\n",
    "display(final_pd.head(10))\n",
    "\n",
    "OUT_FINAL = os.path.join(PROC_DIR, \"weather_countries.parquet\")\n",
    "if os.path.exists(OUT_FINAL): shutil.rmtree(OUT_FINAL)\n",
    "os.makedirs(OUT_FINAL, exist_ok=True)\n",
    "\n",
    "pa_tbl_final = pa.Table.from_pandas(final_pd, preserve_index=False)\n",
    "ds.write_dataset(pa_tbl_final, base_dir=OUT_FINAL, format=\"parquet\",\n",
    "                 partitioning=[\"timestamp_year\",\"timestamp_month\"])\n",
    "\n",
    "print(\"Parquet FINAL salvo em:\", OUT_FINAL)\n",
    "\n",
    "q_final = {\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "    \"row_count\": int(len(final_pd)),\n",
    "    \"null_ratios\": null_ratios(final_pd),\n",
    "    \"temperature_c_range\": {\"min\": float(final_pd[\"temperature_c\"].min()), \"max\": float(final_pd[\"temperature_c\"].max())},\n",
    "    \"humidity_range\": {\"min\": int(final_pd[\"humidity\"].min()), \"max\": int(final_pd[\"humidity\"].max())},\n",
    "    \"population_range\": {\"min\": int(final_pd[\"population\"].min()), \"max\": int(final_pd[\"population\"].max())},\n",
    "}\n",
    "\n",
    "rep_fp_final = os.path.join(REP_DIR, f\"quality_weather_countries_{ts}.json\")\n",
    "with open(rep_fp_final, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(q_final, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Quality FINAL salvo em:\", rep_fp_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3aa0e4-175b-4b75-9465-5059bf78ab9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8- üìä Visualiza√ß√µes ‚Äî **Plotly a partir do Dataset Final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "634aff51-42f0-4448-a841-2bc47a36760b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 8 ‚Äî Visualiza√ß√µes ===\n",
    "import os\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# garante o caminho do parquet final\n",
    "try:\n",
    "    OUT_FINAL\n",
    "except NameError:\n",
    "    OUT_FINAL = os.path.join(PROC_DIR, \"weather_countries.parquet\")\n",
    "\n",
    "# carrega o dataset final\n",
    "dataset_final = ds.dataset(OUT_FINAL, format=\"parquet\")\n",
    "viz_df = dataset_final.to_table().to_pandas()\n",
    "\n",
    "# (opcional) remove linhas 100% duplicadas, caso reexecute o join\n",
    "viz_df = viz_df.drop_duplicates()\n",
    "\n",
    "# --- Gr√°fico 1 (novo): Temperatura √ó Umidade (colorindo por regi√£o) ---\n",
    "# --- Gr√°fico 1 (ajustado com r√≥tulo da cidade) ---\n",
    "fig1 = px.scatter(\n",
    "    viz_df,\n",
    "    x=\"temperature_c\",\n",
    "    y=\"humidity\",\n",
    "    color=\"city\",                \n",
    "    hover_name=\"city\",\n",
    "    hover_data=[\"temperature_c\",\"humidity\",\"humidity_category\",\"timestamp\"],\n",
    "    text=\"city\",  # <<< adiciona r√≥tulo no ponto\n",
    "    title=\"Temperatura (¬∞C) √ó Umidade (%) ‚Äî Capitais BR\"\n",
    ")\n",
    "fig1.update_traces(textposition=\"top center\")  # posi√ß√£o do texto em rela√ß√£o ao ponto\n",
    "fig1.update_xaxes(title=\"Temperatura (¬∞C)\")\n",
    "fig1.update_yaxes(title=\"Umidade (%)\", range=[0, 100])\n",
    "\n",
    "# faixa de conforto 30‚Äì60%\n",
    "fig1.add_hrect(\n",
    "    y0=30, y1=60,\n",
    "    line_width=0, fillcolor=\"LightGreen\", opacity=0.2,\n",
    "    annotation_text=\"Faixa de conforto (30‚Äì60%)\", annotation_position=\"top left\"\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "\n",
    "# --- Gr√°fico 2: Barras - Temperatura atual por capital (com escala de cores) ---\n",
    "fig2 = px.bar(\n",
    "    viz_df.sort_values(\"temperature_c\", ascending=False),\n",
    "    x=\"city\",\n",
    "    y=\"temperature_c\",\n",
    "    color=\"temperature_c\",\n",
    "    color_continuous_scale=\"RdYlBu\",   # azul = frio | vermelho = quente\n",
    "    text=\"temperature_c\",\n",
    "    title=\"Temperatura atual por capital (com valores)\"\n",
    ")\n",
    "fig2.update_traces(texttemplate=\"%{text:.1f}¬∞C\", textposition=\"outside\")\n",
    "fig2.update_layout(xaxis_tickangle=-45, coloraxis_colorbar=dict(title=\"Temperatura (¬∞C)\"))\n",
    "fig2.show()\n",
    "\n",
    "# salvar em HTML\n",
    "os.makedirs(REP_DIR, exist_ok=True)\n",
    "fig1.write_html(os.path.join(REP_DIR, \"scatter_temp_humidity.html\"))\n",
    "fig2.write_html(os.path.join(REP_DIR, \"bar_temperature_by_city.html\"))\n",
    "print(\"Gr√°ficos salvos em:\", REP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9be977a2-3295-41d6-a5bd-a31bbef78694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9- üìÇ Estrutura Final ‚Äî **Raw / Processed / Reports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "751ec4a9-62fc-456f-a985-ed5482a66428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Passo 9 ‚Äî Estrutura Final ===\n",
    "for root, dirs, files in os.walk(BASE_DIR):\n",
    "    level = root.replace(BASE_DIR, \"\").count(os.sep)\n",
    "    indent = \" \" * (2 * level)\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = \" \" * (2 * (level + 1))\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f2aa35a-2e94-4db2-b7a4-b427b5d1c3fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10- üì¶ Empacotamento Final ‚Äî **ZIP do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b0fdf8e-c14c-460b-b89d-ec2040a20f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "ZIP_TARGET = \"/tmp/pipeline_output\"\n",
    "BASE_DIR = \"/tmp/pipeline_api\"  # raiz onde est√° data/raw, processed, reports\n",
    "shutil.make_archive(ZIP_TARGET, \"zip\", BASE_DIR)\n",
    "print(\"ZIP gerado em:\", ZIP_TARGET + \".zip\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Projeto Pr√°tico ‚Äî Pipeline de Dados em Python",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
