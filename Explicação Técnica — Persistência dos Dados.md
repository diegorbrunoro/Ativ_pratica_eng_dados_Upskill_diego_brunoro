# ğŸ“¦ ExplicaÃ§Ã£o TÃ©cnica â€” PersistÃªncia dos Dados

ApÃ³s os tratamentos e transformaÃ§Ãµes, os dados foram **persistidos em formato Parquet particionado**.  
Essa decisÃ£o segue boas prÃ¡ticas de Engenharia de Dados, considerando performance, organizaÃ§Ã£o e consumo futuro.

---

## ğŸ¯ Por que **Parquet**
- Formato **colunar**, ideal para cenÃ¡rios analÃ­ticos.  
- Suporta **compressÃ£o Snappy** (padrÃ£o), reduzindo espaÃ§o e aumentando eficiÃªncia.  
- Permite **leitura seletiva** (apenas colunas necessÃ¡rias sÃ£o lidas).  
- Ã‰ amplamente compatÃ­vel com ecossistemas de Big Data (Spark, Hive, Presto, BigQuery, etc.).

---

## ğŸ—‚ï¸ Por que **Particionamento por ano/mÃªs**
- Otimiza consultas temporais (ex.: `WHERE year=2025 AND month=8`).  
- Evita varrer o dataset inteiro quando se busca um perÃ­odo especÃ­fico.  
- Estrutura o Data Lake de forma escalÃ¡vel.  
- Reflete prÃ¡ticas reais de organizaÃ§Ã£o em pipelines de produÃ§Ã£o.

---

## ğŸš€ ContribuiÃ§Ã£o para Escalabilidade
Se o volume de dados crescer para **milhÃµes de registros por dia** (ex.: coleta de clima a cada minuto em todas as capitais):  
- O **particionamento** garante que apenas as pastas necessÃ¡rias sejam lidas.  
- O **Parquet colunar** garante que apenas as colunas relevantes sejam carregadas em memÃ³ria.  
- Essa combinaÃ§Ã£o permite performance elevada mesmo em cenÃ¡rios de Big Data.

---

## ğŸ”® CenÃ¡rios de Consumo Futuro
- **Spark/Databricks**: leitura direta dos Parquets para anÃ¡lises avanÃ§adas.  
- **Ferramentas BI**: Power BI, Looker, Tableau podem se conectar no diretÃ³rio `processed`.  
- **Pipelines futuros**: agregaÃ§Ãµes semanais/mensais, integraÃ§Ã£o com Data Warehouses (ex.: BigQuery, Snowflake, Redshift).  
- **Armazenamento em nuvem**: estrutura facilmente migrÃ¡vel para buckets em S3, GCS ou Azure Data Lake.

---
